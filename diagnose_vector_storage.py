#!/usr/bin/env python3
"""ë²¡í„° ì €ì¥ì†Œ ì§„ë‹¨ ë„êµ¬"""

import asyncio
import sys
import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional
import traceback

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from src.Config.config import settings
from loguru import logger

logger.remove()
logger.add(sink=sys.stdout, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}")

class VectorStorageDiagnostic:
    """ë²¡í„° ì €ì¥ì†Œ ì§„ë‹¨ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.storage_dir = settings.lightrag_working_dir
        self.issues = []
        self.recommendations = []
    
    def diagnose_directory_structure(self) -> Dict[str, Any]:
        """ë””ë ‰í† ë¦¬ êµ¬ì¡° ì§„ë‹¨"""
        logger.info("\n=== ë””ë ‰í† ë¦¬ êµ¬ì¡° ì§„ë‹¨ ===")
        
        result = {
            "exists": False,
            "readable": False,
            "writable": False,
            "files": [],
            "size_mb": 0
        }
        
        try:
            # ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
            if not self.storage_dir.exists():
                self.issues.append("RAG ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
                self.recommendations.append("python main.py load ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ë¡œë”©í•˜ì„¸ìš”")
                return result
            
            result["exists"] = True
            logger.info(f"âœ… ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ ì¡´ì¬: {self.storage_dir}")
            
            # ê¶Œí•œ í™•ì¸
            result["readable"] = os.access(self.storage_dir, os.R_OK)
            result["writable"] = os.access(self.storage_dir, os.W_OK)
            
            if not result["readable"]:
                self.issues.append("ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ ì½ê¸° ê¶Œí•œ ì—†ìŒ")
            if not result["writable"]:
                self.issues.append("ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ ì—†ìŒ")
            
            # íŒŒì¼ ëª©ë¡ ë° í¬ê¸° í™•ì¸
            total_size = 0
            for file_path in self.storage_dir.rglob("*"):
                if file_path.is_file():
                    file_size = file_path.stat().st_size
                    total_size += file_size
                    result["files"].append({
                        "name": file_path.name,
                        "relative_path": str(file_path.relative_to(self.storage_dir)),
                        "size_bytes": file_size,
                        "size_mb": round(file_size / 1024 / 1024, 2)
                    })
            
            result["size_mb"] = round(total_size / 1024 / 1024, 2)
            logger.info(f"ğŸ“ ì´ íŒŒì¼ ìˆ˜: {len(result['files'])}ê°œ")
            logger.info(f"ğŸ’¾ ì´ í¬ê¸°: {result['size_mb']} MB")
            
            return result
            
        except Exception as e:
            logger.error(f"ë””ë ‰í† ë¦¬ êµ¬ì¡° ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            self.issues.append(f"directory_structure_error: {e}")
            return result
    
    def diagnose_storage_files(self, files_info: List[Dict]) -> Dict[str, Any]:
        """ì €ì¥ì†Œ íŒŒì¼ë“¤ ì§„ë‹¨"""
        logger.info("\n=== ì €ì¥ì†Œ íŒŒì¼ ì§„ë‹¨ ===")
        
        result = {
            "kv_stores": [],
            "vector_stores": [],
            "graphs": [],
            "caches": [],
            "others": [],
            "empty_files": [],
            "corrupted_files": []
        }
        
        try:
            for file_info in files_info:
                file_path = self.storage_dir / file_info["relative_path"]
                file_name = file_info["name"]
                
                # íŒŒì¼ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                if file_info["size_bytes"] == 0:
                    result["empty_files"].append(file_name)
                    continue
                
                # íŒŒì¼ í˜•íƒœë³„ ë¶„ë¥˜
                if file_name.startswith("kv_store_"):
                    result["kv_stores"].append(self._analyze_kv_store(file_path))
                elif file_name.startswith("vector_"):
                    result["vector_stores"].append(self._analyze_vector_store(file_path))
                elif "graph" in file_name:
                    result["graphs"].append(self._analyze_graph_file(file_path))
                elif "cache" in file_name:
                    result["caches"].append(self._analyze_cache_file(file_path))
                else:
                    result["others"].append(file_info)
            
            # ê²°ê³¼ ìš”ì•½
            logger.info(f"ğŸ“š KV ì €ì¥ì†Œ: {len(result['kv_stores'])}ê°œ")
            logger.info(f"ğŸ”¢ ë²¡í„° ì €ì¥ì†Œ: {len(result['vector_stores'])}ê°œ") 
            logger.info(f"ğŸ•¸ï¸ ê·¸ë˜í”„ íŒŒì¼: {len(result['graphs'])}ê°œ")
            logger.info(f"ğŸ’¨ ìºì‹œ íŒŒì¼: {len(result['caches'])}ê°œ")
            logger.info(f"â“ ê¸°íƒ€ íŒŒì¼: {len(result['others'])}ê°œ")
            
            if result["empty_files"]:
                logger.warning(f"âš ï¸ ë¹ˆ íŒŒì¼: {result['empty_files']}")
                self.issues.append(f"ë¹ˆ íŒŒì¼ë“¤ì´ ë°œê²¬ë¨: {result['empty_files']}")
            
            if result["corrupted_files"]:
                logger.error(f"âŒ ì†ìƒëœ íŒŒì¼: {result['corrupted_files']}")
                self.issues.append(f"ì†ìƒëœ íŒŒì¼ë“¤ì´ ë°œê²¬ë¨: {result['corrupted_files']}")
            
            return result
            
        except Exception as e:
            logger.error(f"ì €ì¥ì†Œ íŒŒì¼ ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            self.issues.append(f"storage_files_error: {e}")
            return result
    
    def _analyze_kv_store(self, file_path: Path) -> Dict[str, Any]:
        """KV ì €ì¥ì†Œ íŒŒì¼ ë¶„ì„"""
        result = {
            "file": file_path.name,
            "type": "kv_store",
            "valid": False,
            "entries_count": 0,
            "sample_keys": []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            result["valid"] = True
            result["entries_count"] = len(data) if isinstance(data, dict) else 0
            
            if isinstance(data, dict):
                result["sample_keys"] = list(data.keys())[:5]  # ì²˜ìŒ 5ê°œ í‚¤ë§Œ
            
            logger.info(f"  âœ… {file_path.name}: {result['entries_count']}ê°œ í•­ëª©")
            
        except json.JSONDecodeError:
            logger.error(f"  âŒ {file_path.name}: JSON íŒŒì‹± ì˜¤ë¥˜")
            result["valid"] = False
        except Exception as e:
            logger.error(f"  âŒ {file_path.name}: ë¶„ì„ ì˜¤ë¥˜ - {e}")
            result["valid"] = False
        
        return result
    
    def _analyze_vector_store(self, file_path: Path) -> Dict[str, Any]:
        """ë²¡í„° ì €ì¥ì†Œ íŒŒì¼ ë¶„ì„"""
        result = {
            "file": file_path.name,
            "type": "vector_store", 
            "valid": False,
            "vectors_count": 0,
            "dimensions": 0
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            result["valid"] = True
            
            if isinstance(data, dict):
                result["vectors_count"] = len(data)
                # ì²« ë²ˆì§¸ ë²¡í„°ì˜ ì°¨ì› í™•ì¸
                if data:
                    first_vector = next(iter(data.values()))
                    if isinstance(first_vector, list):
                        result["dimensions"] = len(first_vector)
            
            logger.info(f"  âœ… {file_path.name}: {result['vectors_count']}ê°œ ë²¡í„°, {result['dimensions']}ì°¨ì›")
            
        except json.JSONDecodeError:
            logger.error(f"  âŒ {file_path.name}: JSON íŒŒì‹± ì˜¤ë¥˜")
            result["valid"] = False
        except Exception as e:
            logger.error(f"  âŒ {file_path.name}: ë¶„ì„ ì˜¤ë¥˜ - {e}")
            result["valid"] = False
        
        return result
    
    def _analyze_graph_file(self, file_path: Path) -> Dict[str, Any]:
        """ê·¸ë˜í”„ íŒŒì¼ ë¶„ì„"""
        result = {
            "file": file_path.name,
            "type": "graph",
            "valid": False,
            "size_mb": round(file_path.stat().st_size / 1024 / 1024, 2)
        }
        
        try:
            # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ë‹¤ë¥¸ ë¶„ì„
            if file_path.suffix == ".json":
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                result["valid"] = True
            else:
                # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì¸ ê²½ìš° í¬ê¸°ë§Œ í™•ì¸
                result["valid"] = file_path.stat().st_size > 0
            
            logger.info(f"  âœ… {file_path.name}: {result['size_mb']} MB")
            
        except Exception as e:
            logger.error(f"  âŒ {file_path.name}: ë¶„ì„ ì˜¤ë¥˜ - {e}")
            result["valid"] = False
        
        return result
    
    def _analyze_cache_file(self, file_path: Path) -> Dict[str, Any]:
        """ìºì‹œ íŒŒì¼ ë¶„ì„"""
        result = {
            "file": file_path.name,
            "type": "cache",
            "valid": False,
            "entries_count": 0
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            result["valid"] = True
            result["entries_count"] = len(data) if isinstance(data, dict) else 0
            
            logger.info(f"  âœ… {file_path.name}: {result['entries_count']}ê°œ ìºì‹œ í•­ëª©")
            
        except Exception as e:
            logger.error(f"  âŒ {file_path.name}: ë¶„ì„ ì˜¤ë¥˜ - {e}")
            result["valid"] = False
        
        return result
    
    def check_embedding_consistency(self, storage_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ì„ë² ë”© ì¼ê´€ì„± í™•ì¸"""
        logger.info("\n=== ì„ë² ë”© ì¼ê´€ì„± í™•ì¸ ===")
        
        result = {
            "expected_dimension": settings.embedding_dim or 1024,
            "found_dimensions": [],
            "consistent": True,
            "total_vectors": 0
        }
        
        try:
            for vector_store in storage_analysis.get("vector_stores", []):
                if vector_store["valid"] and vector_store["dimensions"] > 0:
                    result["found_dimensions"].append(vector_store["dimensions"])
                    result["total_vectors"] += vector_store["vectors_count"]
            
            # ì°¨ì› ì¼ê´€ì„± í™•ì¸
            unique_dimensions = set(result["found_dimensions"])
            if len(unique_dimensions) > 1:
                result["consistent"] = False
                self.issues.append(f"ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜: {unique_dimensions}")
                self.recommendations.append("rag_storage ë””ë ‰í† ë¦¬ë¥¼ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ë¬¸ì„œë¥¼ ë¡œë”©í•˜ì„¸ìš”")
            
            expected_dim = result["expected_dimension"]
            if unique_dimensions and expected_dim not in unique_dimensions:
                result["consistent"] = False
                self.issues.append(f"ì„¤ì •ëœ ì°¨ì›({expected_dim})ê³¼ ì‹¤ì œ ì°¨ì›({unique_dimensions}) ë¶ˆì¼ì¹˜")
                self.recommendations.append(f".env íŒŒì¼ì˜ EMBEDDING_DIMì„ {list(unique_dimensions)[0]}ë¡œ ìˆ˜ì •í•˜ì„¸ìš”")
            
            logger.info(f"ğŸ“ ì˜ˆìƒ ì°¨ì›: {expected_dim}")
            logger.info(f"ğŸ” ë°œê²¬ëœ ì°¨ì›: {unique_dimensions}")
            logger.info(f"ğŸ“Š ì´ ë²¡í„° ìˆ˜: {result['total_vectors']}")
            
            if result["consistent"]:
                logger.info("âœ… ì„ë² ë”© ì°¨ì› ì¼ê´€ì„± OK")
            else:
                logger.warning("âš ï¸ ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜ ë°œê²¬")
            
            return result
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ì¼ê´€ì„± í™•ì¸ ì‹¤íŒ¨: {e}")
            self.issues.append(f"embedding_consistency_error: {e}")
            return result
    
    def suggest_solutions(self):
        """í•´ê²°ì±… ì œì•ˆ"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ”§ ì§„ë‹¨ ê²°ê³¼ ë° í•´ê²°ì±…")
        logger.info("="*60)
        
        if not self.issues:
            logger.info("âœ… ë²¡í„° ì €ì¥ì†Œ ìƒíƒœê°€ ì •ìƒì…ë‹ˆë‹¤!")
            return
        
        logger.info("âš ï¸ ë°œê²¬ëœ ë¬¸ì œì :")
        for i, issue in enumerate(self.issues, 1):
            logger.info(f"  {i}. {issue}")
        
        logger.info("\nğŸ’¡ ì¶”ì²œ í•´ê²°ì±…:")
        for i, rec in enumerate(self.recommendations, 1):
            logger.info(f"  {i}. {rec}")
        
        # ì¶”ê°€ ì¼ë°˜ì ì¸ í•´ê²°ì±…
        logger.info("\nğŸ› ï¸ ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•:")
        logger.info("  â€¢ ì„ë² ë”© í…ŒìŠ¤íŠ¸: python test_embedding.py")
        logger.info("  â€¢ RAG ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸: python test_rag_workflow.py") 
        logger.info("  â€¢ ë¬¸ì„œ ì¬ë¡œë”©: python main.py load")
        logger.info("  â€¢ ì €ì¥ì†Œ ì´ˆê¸°í™”: rm -rf rag_storage && python main.py load")
        logger.info("  â€¢ Ollama ëª¨ë¸ í™•ì¸: ollama list")
        logger.info("  â€¢ Ollama ì„ë² ë”© ëª¨ë¸ ì„¤ì¹˜: ollama pull bge-m3:latest")
    
    async def run_full_diagnosis(self) -> Dict[str, Any]:
        """ì „ì²´ ì§„ë‹¨ ì‹¤í–‰"""
        logger.info("ğŸ” ë²¡í„° ì €ì¥ì†Œ ì „ì²´ ì§„ë‹¨ ì‹œì‘")
        
        diagnosis_result = {
            "directory": {},
            "files": {},
            "embedding": {},
            "issues_count": 0,
            "recommendations_count": 0
        }
        
        try:
            # 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° ì§„ë‹¨
            diagnosis_result["directory"] = self.diagnose_directory_structure()
            
            # 2. ì €ì¥ì†Œ íŒŒì¼ë“¤ ì§„ë‹¨ (ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ)
            if diagnosis_result["directory"]["exists"]:
                diagnosis_result["files"] = self.diagnose_storage_files(
                    diagnosis_result["directory"]["files"]
                )
                
                # 3. ì„ë² ë”© ì¼ê´€ì„± í™•ì¸
                diagnosis_result["embedding"] = self.check_embedding_consistency(
                    diagnosis_result["files"]
                )
            
            # 4. ê²°ê³¼ ìš”ì•½ ë° í•´ê²°ì±… ì œì•ˆ
            diagnosis_result["issues_count"] = len(self.issues)
            diagnosis_result["recommendations_count"] = len(self.recommendations)
            
            self.suggest_solutions()
            
            return diagnosis_result
            
        except Exception as e:
            logger.error(f"ì§„ë‹¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            logger.error(traceback.format_exc())
            return diagnosis_result

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        diagnostic = VectorStorageDiagnostic()
        result = await diagnostic.run_full_diagnosis()
        
        # ì¢…ë£Œ ì½”ë“œ ì„¤ì •
        if result["issues_count"] == 0:
            sys.exit(0)  # ë¬¸ì œ ì—†ìŒ
        else:
            sys.exit(1)  # ë¬¸ì œ ë°œê²¬
            
    except KeyboardInterrupt:
        logger.info("\nì§„ë‹¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ì§„ë‹¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())