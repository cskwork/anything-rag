# LLM 제공자 선택 - 우선순위: local → ollama → openrouter
# Options: auto, local, ollama, openai, openrouter
LLM_PROVIDER=auto

# LLM 서비스 설정
LOCAL_API_HOST=http://localhost:3284

OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gemma3:1b
OLLAMA_EMBEDDING_MODEL=bge-m3:latest

OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=anthropic/claude-3-haiku

# LightRAG 설정
LIGHTRAG_WORKING_DIR=./rag_storage
LIGHTRAG_CHUNK_SIZE=1200
LIGHTRAG_CHUNK_OVERLAP=100
LIGHTRAG_EMBEDDING_MODEL=bge-m3:latest
LIGHTRAG_HISTORY_TURNS=3

# 시스템 설정
LOG_LEVEL=INFO
LANGUAGE=ko
MAX_TOKENS=2000
TEMPERATURE=0.5
EMBEDDING_DIM=

# 문서 처리 설정
SUPPORTED_EXTENSIONS=.txt,.pdf,.docx,.md,.xlsx
MAX_FILE_SIZE_MB=50
ENCODING=utf-8

# 디렉토리 설정
INPUT_DIR=./input
BACKUP_DIR=./backup
LOGS_DIR=./logs